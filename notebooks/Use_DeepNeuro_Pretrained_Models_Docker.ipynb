{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "![DeepNeuro](https://github.com/QTIM-Lab/DeepNeuro/raw/master/package_resources/logos/DeepNeuro_alt.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Running a DeepNeuro Module with Docker\n",
    "\n",
    "In this notebook, you will learn how to run a DeepNeuro module from its Docker container. DeepNeuro modules are scripts created with DeepNeuro syntax, and their goal is usually to: load data from any state of preprocessing, run inference on a model trained to accomplish a certain task, and save out to the results to a location of your choosing. Today, we will be running the glioma segmentation module in DeepNeuro.\n",
    "\n",
    "You will need to have Docker already installed for this tutorial. You can find some instructions on how to do that here: https://docs.docker.com/install/. Some tutorials on how to use Docker can be found here: https://docker-curriculum.com/.\n",
    "\n",
    "In order to run these Docker containers on the GPU, you will also have to install nvidia-docker. nvidia-docker is an extension to Docker that lets you seamlessly hook up your docker containers to your NVIDIA GPU drivers and supporting software. You can find instructions on how to install nvidia-docker here: https://github.com/NVIDIA/nvidia-docker.\n",
    "\n",
    "You can find documentation for the glioma segmentation module at this link: https://github.com/QTIM-Lab/DeepNeuro/tree/master/deepneuro/pipelines/Segment_GBM. Don't worry about reading it too much right now -- we will go over the parameters in this tutorial too.\n",
    "\n",
    "Our first step will be to pull the Docker container for glioma segmentation with DeepNeuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from qtimlab/deepneuro_segment_gbm\n",
      "Digest: sha256:890f03b339354f3a35aadf98045773f23d13b15ddf11df5680c7d3d68247cb3f\n",
      "Status: Image is up to date for qtimlab/deepneuro_segment_gbm:latest\n"
     ]
    }
   ],
   "source": [
    "!docker pull qtimlab/deepneuro_segment_gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Easy enough! We will also have to download our medical imaging data. If you haven't already downloaded it in a previous tutorial, you can get download it from DeepNeuro with the following command. We will be loading a DICOM dataset this time, instead of a NIfTI dataset, to show off some of the preprocessing steps that come prepackaged in DeepNeuro Docker containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sample_gbm_dicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5377918b6a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepneuro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_gbm_dicom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_datapath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./Sample_Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/abeers/Github/DeepNeuro/deepneuro/load/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(dataset, output_datapath)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_datapath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sample_gbm_dicom'"
     ]
    }
   ],
   "source": [
    "from deepneuro.load.load import load\n",
    "\n",
    "training_data_sources = {\n",
    "    'directories': {\n",
    "                './Sample_Data/GBM_NIFTI/TRAINING':\n",
    "                {'input_data': ['*_flair.nii.gz*', '*_t2.nii.gz*', '*_t1.nii.gz', '*_t1Gd.nii.gz'], \n",
    "                 'ground_truth': ['*GlistrBoost_ManuallyCorrected.nii.gz']}},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the folder you just downloaded, you should see four subfolders corresponding to T2, FLAIR, pre-contrast T1, and post-contrast T1 MR sequences. These images are not the same resolution, are not registered to the same patient space, are not on the same intensity scale, and have not otherwise been preprocessed. Luckily, we have a Docker container that can do all of those things, and even segment glioma tissue at the end of the process!\n",
    "\n",
    "There are two principle ways to run a Docker container in DeepNeuro. One is directly via the Docker interface: simply construct a command and enter it into the command-line. The other is via DeepNeuro's Docker wrapper, written in Python. The latter takes care of some of the difficulties of working with Docker, and let's you run Docker containers from within a Python script, but requires you to have a local installation of DeepNeuro.\n",
    "\n",
    "## Running a Module via Docker and the Command Line\n",
    "\n",
    "If you are familiar with Docker containers, running DeepNeuro via the Docker interface may seem like the easiest option to you. Docker (and nvidia-docker) has its own interface for structuring command-line requests that we will follow in this portion of the tutorial.\n",
    "\n",
    "Running containers with Docker and nvidia-docker can be easy. You begin all commands with \"nvidia-docker run\".\n",
    "\n",
    "_Note that command line functions in Jupyter/Colab need to be preceded by a exclamation point. You will not need to do this on your own command line._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So good so far. The next step is to add the \"--rm\" parameter. This command makes sure that upon completion of a container's task (in this case, deep learning inference), that Docker is shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run --rm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The next step is to specify the container you want to run. In this tutorial, we will be running the deepneuro_segment_gbm container. You access this container by pulling it from our lab's repository, \"qtimlab\". Thus our repository name in this command will be \"qtimlab/deepneuro_segment_gbm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run --rm qtimlab/deepneuro_segment_gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That's all it takes to get a Docker container running! But not all that it takes to get it running and _doing something you want to do_. We'll need some more steps for that part. Particularly, we will need to submit additional commands to the Docker container to specify the action it should take. This is specified in this module's documentation, but the command you should add on is \"segment_gbm pipeline\". This means that DeepNeuro will run through the entire data preprocessing and segmentation pipelines for this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run --rm qtimlab/deepneuro_segment_gbm segment_gbm pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The last step is often the most difficult part for those just getting started with Docker. We have the command, but we haven't specified what data we want to run our container on it yet.\n",
    "\n",
    "Docker requires you to mount directories on your operating system to folders inside the Docker container. Otherwise, your Docker container would not be able to access any of your files. DeepNeuro requires that you mount all data for processing into a folder titled \"/INPUT_DATA\". To add this to mounted directory to your docker command, you append the following parameter to your nvidia-docker call \"-v [your_input_directory]:/INPUT_DATA\".\n",
    "\n",
    "Unfortunately, knowing which input directory to mount isn't obvious, so let's work through an example. Say that you had some data on your workstation in this folder:\n",
    "\n",
    "`/home/your_username/my_imaging_data/Patient_1`\n",
    "\n",
    "With three folders inside of it containing DICOM data from three different MR sequences. Let's say these folders had the following names:\n",
    "\n",
    "* `/home/your_username/my_imaging_data/Patient_1/T1_Pre_Contrast`\n",
    "* `/home/your_username/my_imaging_data/Patient_1/T1_Post_Contrast`\n",
    "* `/home/your_username/my_imaging_data/Patient_1/FLAIR`\n",
    "\n",
    "And let's say you wanted to output your segmentations to a new folder located at this filepath:\n",
    "\n",
    "`/home/your_username/results/Patient_1/Segmentation`\n",
    "\n",
    "Which directory should you mount? The answer is \"/home/your_username/\". This is the mounted directory that contains all of the folders you need to process data with DeepNeuro. So, the command will be formatted this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run --rm -v /home/your_username:/INPUT_DATA qtimlab/deepneuro_segment_gbm segment_gbm pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "All that's left is to fill in the parameters for your segmentation command accordingly. These parameters should be listed [on the documentation page for this module](https://github.com/QTIM-Lab/DeepNeuro/tree/master/deepneuro/pipelines/Segment_GBM). Note that any filepath you use will be relative to `/INPUT_DATA` rather than whatever the filepath is on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-docker run --rm -v /home/your_username:/INPUT_DATA qtimlab/deepneuro_segment_gbm segment_gbm pipeline \\\n",
    "    -T1 /INPUT_DATA/my_imaging_data/Patient_1/T1_Pre_Contrast \\\n",
    "    -T1POST /INPUT_DATA/my_imaging_data/Patient_1/T1_Post_Contrast \\\n",
    "    -FLAIR /INPUT_DATA/my_imaging_data/Patient_1/FLAIR \\\n",
    "    -output_folder /INPUT_DATA/results/Patient_1/Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And that's the full command! There are, of course, other parameters you can add on to the end of the command on [the documentation page](https://github.com/QTIM-Lab/DeepNeuro/tree/master/deepneuro/pipelines/Segment_GBM) if you wish you customize your command further.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
